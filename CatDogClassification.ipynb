{"cells":[{"cell_type":"markdown","metadata":{"id":"zpxfhoaRJRqa"},"source":["\n","## Lab-10: Cat Dog Classification with CNNs\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":768,"status":"ok","timestamp":1672381517612,"user":{"displayName":"Muhammad Abrar Hussain","userId":"01130748540043358277"},"user_tz":-300},"id":"VOfnBz3ZJRqa"},"outputs":[],"source":["#Importing libraries\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import shutil\n","import sys\n","from glob import glob\n","from keras.preprocessing import image\n","from tensorflow.keras.preprocessing import image\n","from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPool2D\n","from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Input\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from glob import glob\n","from tensorflow.keras.preprocessing import image"]},{"cell_type":"markdown","metadata":{"id":"DSsLBch-trqt"},"source":["## Part 1: Importing the dataset from Kaggle\n","\n","Before we start, lets get some of the basic steps cleared: \u003cbr\u003e\n","\u003ch5\u003e 1. Create a Kaggle account\u003c/h5\u003e\n","\n","- Create an account on Kaggle.com - this is mandatory, since we will be accessing the dataset from Kaggle directly in Google Colab.\n","- Next go to the link given : https://www.kaggle.com/c/dogs-vs-cats/data. This is the dataset we will be using for this lab. \n","\n","\u003ch5\u003e 2. Get the dataset to Google colab\u003c/h5\u003e\n","\n","- On your account on Kaggle - top right corner of the page [Profile , **Account**, Sign Out] - Click on account and scroll down to APIs. \n","- Here create a new API token - you should get an option to download a **kaggle.json** file"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":3682,"status":"ok","timestamp":1672381531596,"user":{"displayName":"Muhammad Abrar Hussain","userId":"01130748540043358277"},"user_tz":-300},"id":"RmQoValy1qie"},"outputs":[],"source":["#Install kaggle\n","! pip install -q kaggle"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":38},"id":"paWETkCf1unt"},"outputs":[{"data":{"text/html":["\n","     \u003cinput type=\"file\" id=\"files-5b4afe6a-ac2d-4aba-a0fd-fd55ca760870\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" /\u003e\n","     \u003coutput id=\"result-5b4afe6a-ac2d-4aba-a0fd-fd55ca760870\"\u003e\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      \u003c/output\u003e\n","      \u003cscript\u003e// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) =\u003e {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable\u003c!Object\u003e} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) =\u003e {\n","    inputElement.addEventListener('change', (e) =\u003e {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) =\u003e {\n","    cancel.onclick = () =\u003e {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) =\u003e {\n","      const reader = new FileReader();\n","      reader.onload = (e) =\u003e {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position \u003c fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","\u003c/script\u003e "],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"ename":"TypeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-8-3e0ce4f51b84\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Upload the kaggle.json file you just downloaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 3\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m   \"\"\"\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 67\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    147\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 149\u001b[0;31m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     result = _output.eval_js(\n\u001b[1;32m    151\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n","\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"]}],"source":["#Upload the kaggle.json file you just downloaded\n","from google.colab import files\n","files.upload()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"HduVOx__lU2c"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SBtjUdLkH6Mb"},"outputs":[],"source":["#Make directory named kaggle \n","!mkdir ~/.kaggle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dpeTX5eUPA1S"},"outputs":[],"source":["# copy kaggle.json file there.\n","! cp kaggle.json ~/.kaggle/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"So2XADshPM9l"},"outputs":[],"source":["#change the permissions of the file\n","! chmod 600 ~/.kaggle/kaggle.json "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"980e7Pevtrq0"},"outputs":[],"source":["# Download the dataset zip in this location \n","DATA_DIR = '../data' \n","IMAGE_DIR= '../data/image'\n","!mkdir ../data\n","!mkdir ../data/dogs-vs-cats\n","!mkdir ../data/images"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1892,"status":"ok","timestamp":1672381176367,"user":{"displayName":"Muhammad Abrar Hussain","userId":"01130748540043358277"},"user_tz":-300},"id":"Jow5huM6trq2","outputId":"5e18e015-cf1e-4c2b-872d-34bbbd2c5f92"},"outputs":[{"name":"stdout","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/usr/local/bin/kaggle\", line 5, in \u003cmodule\u003e\n","    from kaggle.cli import main\n","  File \"/usr/local/lib/python3.8/dist-packages/kaggle/__init__.py\", line 23, in \u003cmodule\u003e\n","    api.authenticate()\n","  File \"/usr/local/lib/python3.8/dist-packages/kaggle/api/kaggle_api_extended.py\", line 164, in authenticate\n","    raise IOError('Could not find {}. Make sure it\\'s located in'\n","OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"]}],"source":["#downloading the dataset from Kaggle\n","!kaggle competitions download -c dogs-vs-cats -p {DATA_DIR}"]},{"cell_type":"markdown","metadata":{"id":"B9NjkXFWtrq6"},"source":["Unzip the file and delete the other unnecessary files and original zip."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tcJL_i0Ltrq9"},"outputs":[],"source":["#Unzipping\n","shutil.unpack_archive(os.path.join(DATA_DIR,'dogs-vs-cats.zip'), DATA_DIR)\n","os.remove(os.path.join(DATA_DIR, 'dogs-vs-cats.zip')) \n","# changing the data directory to KAGGLE_DIR\n","KAGGLE_DIR = os.path.join(DATA_DIR, 'dogs-vs-cats')\n","shutil.unpack_archive(os.path.join(DATA_DIR, 'train.zip'), IMAGE_DIR)\n","os.remove(os.path.join(DATA_DIR, 'train.zip'))\n","shutil.unpack_archive(os.path.join(DATA_DIR, 'test1.zip'), IMAGE_DIR)\n","os.remove(os.path.join(DATA_DIR, 'test1.zip'))\n","\n","os.remove(os.path.join(DATA_DIR, 'sampleSubmission.csv'))\n"]},{"cell_type":"markdown","metadata":{"id":"CjRt7xUiJRqb"},"source":["The dogs and cats are all mixed in a single directory. The label is in the file name itself.\u003c/br\u003e\n","We need to create:\n","1. Train, validation, and test directories, each containing a subset of the images.\n","2. Separate cat and dog directories _within_ train, validation, and test.\n","\n","Number 2 is necessary because the Keras ImageDataGenerator's flow_from_directory() method infers the class label from the subdirectory the image resides in.\n","\n","Therefore, we need to create a directory structure as seen below:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ss0bRM1_JRqb"},"outputs":[],"source":["# dogs_vs_cats\n","# ├── test\n","# │   ├── cats\n","# │   └── dogs\n","# ├── train\n","# |   ├── cats\n","# |   └── dogs\n","# └── validation\n","#     ├── cats\n","#     └── dogs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jVs_mlB4JRqb"},"outputs":[],"source":["# Create train, validation, and test directories\n","split_dirs = ['train', 'validation', 'test']\n","for split_dir in split_dirs:\n","    # create label subdirectories\n","    label_dirs = ['dogs', 'cats']\n","    for label_dir in label_dirs:\n","        new_dir = os.path.join(KAGGLE_DIR, split_dir, label_dir)\n","        os.makedirs(new_dir, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sRZYjLA5JRqb","scrolled":true},"outputs":[],"source":["# copy dataset images into subdirectories based on probability distribution 'p'\n","PERCENT_OF_DATA = 0.1\n","np.random.seed(42)\n","for folder in os.listdir(KAGGLE_DIR):\n","  for file in os.listdir(os.path.join(IMAGE_DIR,folder)):\n","    if not file.endswith('.jpg'):\n","        continue # skip over non-image files\n","    src = os.path.join(IMAGE_DIR,folder, file)\n","    if np.random.uniform() \u003e PERCENT_OF_DATA:\n","        os.remove(src)\n","        continue\n","    dst_dir = np.random.choice(['train', 'validation', 'test'], p=[.5, .25, .25])\n","    if file.startswith('cat'):\n","        dst = os.path.join(KAGGLE_DIR, dst_dir, 'cats', file)\n","    elif file.startswith('dog'):\n","        dst = os.path.join(KAGGLE_DIR, dst_dir, 'dogs', file)\n","    try:\n","        shutil.move(src, dst)\n","    except Exception as e:\n","        print(e)\n","#Remove these empty diretories\n","shutil.rmtree(IMAGE_DIR)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q2p6mEcAJRqb"},"outputs":[],"source":["#Number of images in each subdir\n","for dir_name in split_dirs:\n","    for label_dir in label_dirs:\n","        print(dir_name ,label_dir, len(os.listdir(KAGGLE_DIR + '/' + dir_name + '/' + label_dir)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_zr4G59wJRqb"},"outputs":[],"source":["# Preprocessing the image into a 4D tensor\n","img_path = glob(KAGGLE_DIR+'/*/*/*.jpg')[0]\n","\n","img = image.load_img(img_path, target_size=(150, 150))\n","img_tensor = image.img_to_array(img)\n","img_tensor = np.expand_dims(img_tensor, axis=0)\n","img_tensor /= 255.\n","\n","print(img_tensor.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wv5dgA_uVHuZ"},"outputs":[],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YhNDdr_gJRqb"},"outputs":[],"source":["# Displaying an example img\n","plt.imshow(img_tensor[0])\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"cRk8QDQVwQ6F"},"source":["## Part 2: Creating the Generators and training a model with only rescaled images"]},{"cell_type":"markdown","metadata":{"id":"bPLV0-AeJRqb"},"source":["\u003cb\u003eCreate the Generators\u003c/b\u003e\n","\n","Now that we have the data in the correct directory structure we can create the data generators.\n","Yes, that's correct. We will have _multiple_ generators, one for each split directory.\u003cbr\u003e\n","\n","\n","First we create a main data generator object, `datagen`. This can be a given a wide range of arguments which can be used to preprocess the images it generates.\u003c/br\u003e\n","\n","\u003cb\u003eFor right now we will only use the `rescale` argument to normalize all pixel values to between 0 and 1 (remember that 255 is the max pixel value).\u003c/b\u003e"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZmO6bBUeJRqb"},"outputs":[],"source":["datagen = ImageDataGenerator(rescale=1/255)"]},{"cell_type":"markdown","metadata":{"id":"lpqqealsJRqb"},"source":["Now we use `datagen`'s `flow_from_directory` method to create the 3 generators: `traingen`, `valgen`, and `testgen`.\u003cbr\u003e\n","\n","The function needs to be given the following parameters:\u003cbr\u003e\n","- `directory` which they will use as their image source\n","- `target_size` to resize all images to (75,75)\n","- `batch_size`\n","- `class_mode` to instruct the generator on how to interpret the label folders. \n","\n","We should probably also set `shuffle = False` in the test generator so it produces the same images in the same order everytime it is used."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L9ZsFxc4JRqb"},"outputs":[],"source":["batch_size = 16\n","target_size = (75, 75)\n","\n","traingen = datagen.flow_from_directory(directory='/data/dogs-vs-cats/train', target_size=target_size, batch_size=batch_size, class_mode='categorical')\n"," \n","valgen = datagen.flow_from_directory(directory='/data/dogs-vs-cats/validation', target_size=target_size, batch_size=batch_size, class_mode='categorical')\n","\n","testgen = datagen.flow_from_directory(directory='/data/dogs-vs-cats/test', target_size=target_size, batch_size=batch_size, class_mode='categorical')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ziXISgtbu_ak"},"outputs":[],"source":["print(\"Class indices:\", traingen.class_indices)\n"]},{"cell_type":"markdown","metadata":{"id":"fCSWExdXtrrY"},"source":["### Construct CNN MODEL\n","\n","- Build the CNN Model, there is no limitation on number of layers or size of the CNN Model, we leave the design choices to you.  For more information on layers :[CNN modelling](https://keras.io/api/layers/convolution_layers/convolution2d/)\n","- Fit the model using Model.fit()\n","- Evaluate your model \n","- Plot your results\n","- Save your model \n","We would love to see these results in Tensorboard along with the computation graph.\n","\n","You can regularize the model as well. For reference: https://keras.io/api/callbacks/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"inOd6TwUJRqb"},"outputs":[],"source":["#Creating a CNN\n","CNN = Sequential()\n","\n","CNN.add(Input(shape=(75, 75, 3)))\n","\n","#Specify a list of the number of filters for each convolutional layer\n","\n","for n_filters in [16, 32, 64]:\n","    CNN.add(Conv2D(n_filters,strides=(2, 2), kernel_size=3, activation='relu'))\n","\n","# Fill in the layer needed between our 2d convolutional layers and the dense layer\n","CNN.add(Flatten())\n","\n","#Specify the number of nodes in the dense layer before the output\n","CNN.add(Dense(128, activation='relu'))\n","\n","#Specify the output layer\n","CNN.add(Dense(2, activation='softmax'))\n"," \n","#Compiling the model\n","CNN.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"LtrAYn3NwTmI"},"source":["**Plot model Diagram**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"308iQjGWv3-y"},"outputs":[],"source":["plot_model(ConnectionResetError, show_shapes=True, show_layer_names=False, dpi=60)"]},{"cell_type":"markdown","metadata":{"id":"JShV77UDJRqc"},"source":["\u003cb\u003eFit Model\u003c/b\u003e\n","\n","Let’s fit the model to the data using the generator. You can use `fit` as before but this time you will pass it generators rather than dataframes or numpy arrays.  \n","\n","Because the data is being generated endlessly, the Keras model needs to know how many samples to draw from the generator before declaring an epoch over. This is the role of the `steps_per_epoch` argument: after having drawn steps_per_epoch batches from the generator—that is, after having run for steps_per_epoch gradient descent steps - the fitting process will go to the next epoch. \n","\n","When using `fit`, you can pass a validation_data argument. It’s important to note that this argument is allowed to be a data generator, but it could also be a tuple of Numpy arrays. If you pass a generator as validation_data, then this generator is expected to yield batches of validation data endlessly; thus you should also specify the validation_steps argument, which tells the process how many batches to draw from the validation generator for evaluation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uH6HTeTuJRqc","scrolled":true},"outputs":[],"source":["# Training the CNN model\n","history = CNN.fit(traingen,\n","        epochs=20,\n","        validation_data=valgen)"]},{"cell_type":"markdown","metadata":{"id":"B3bmLMk1JRqc"},"source":["\u003cb\u003eEvaluate the Model\u003c/b\u003e"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RMmch-v2JRqc"},"outputs":[],"source":["CNN.evaluate(testgen)"]},{"cell_type":"markdown","metadata":{"id":"o24FgrJjJRqc"},"source":["Let’s plot the loss and accuracy of the model over the training and validation data during training:"]},{"cell_type":"markdown","metadata":{"id":"tPRptu06JRqc"},"source":["\u003cb\u003ePlot the Training History\u003c/b\u003e\n","\n","Plot the training and validation accuracy and loss."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rDtPb7jdJRqc"},"outputs":[],"source":["# Plotting the loss and accuracy plots\n","fig, ax = plt.subplots(1,2,figsize=(10,5))\n","ax[0].plot(history.history['loss'], label=\"Train Loss\")\n","ax[0].plot(history.history['val_loss'], label=\"Val Loss\")\n","ax[1].plot(history.history['accuracy'], label=\"Train Accuracy\")\n","ax[1].plot(history.history['val_accuracy'], label=\"Val Accuracy\")\n","ax[0].legend()\n","ax[1].legend()\n","ax[0].set_title(\"Loss Plot\")\n","ax[1].set_title(\"Accuracy Plot\")"]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":0}